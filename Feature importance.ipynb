{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNkM3FNMWJ4B7odWiwUGqwO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","\n","## Mean Decrease in Impurity (MDI)\n","\n","**What is it?**  \n","The default “feature importance” metric in decision‑tree and tree‑ensemble libraries (e.g., `RandomForestClassifier`, `GradientBoostingClassifier` in scikit‑learn).  \n","> “Across all splits using feature _j_, how much did those splits reduce impurity?”\n","\n","---\n","\n","### 1. Node impurity\n","- **Classification**  \n","  - Gini:  \n","    $G = 1 - \\sum_{k=1}^K p_k^2$  \n","  - Entropy:  \n","    $H = -\\sum_{k=1}^K p_k \\log p_k$\n","- **Regression**  \n","  - Mean squared error:  \n","    $I = \\tfrac{1}{n}\\sum_i (y_i - \\bar y)^2$\n","\n","---\n","\n","### 2. Impurity decrease for one split\n","For node _t_ with _nₜ_ samples and impurity $I(t)$, split into left _L_ and right _R_:\n","\n","$$\n","\\Delta I(t,j) = I(t) - \\Bigl(\\tfrac{n_L}{n_t}I(L) + \\tfrac{n_R}{n_t}I(R)\\Bigr)\n","$$\n","\n","---\n","\n","### 3. From one tree to many\n","- **Single tree**:  \n","  $\\text{MDI}_j = \\sum_{t:\\,feat(t)=j} \\Delta I(t,j)$\n","\n","- **Ensemble of M trees**:  \n","  $$\n","  \\frac{1}{M}\\sum_{m=1}^M \\text{MDI}_j^{(m)}\n","  $$  \n","  (Often normalized so $\\sum_j \\text{MDI}_j = 1$)\n","\n","---\n","\n","### 4. Key caveats\n","1. **Bias** toward high‑cardinality/continuous features  \n","2. **Underestimates** correlated features  \n","3. **Model‑specific**, not causal  \n","4. **Global only** (no sample‑level insight)\n","\n","---\n","\n","### 5. Quick recipe\n","1. Train your tree ensemble.  \n","2. Sum impurity drops per feature across all splits & trees.  \n","3. (Optionally) normalize to sum to 1.\n","\n"],"metadata":{"id":"QFTv1cdQE0tg"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.ensemble import RandomForestClassifier\n","import pandas as pd\n","\n","# Load data\n","X, y = load_iris(return_X_y=True)\n","feature_names = load_iris().feature_names\n","\n","# Train\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X, y)\n","\n","# Extract MDI importances\n","importances = rf.feature_importances_\n","df_imp = pd.DataFrame({\n","    'feature': feature_names,\n","    'MDI_importance': importances\n","}).sort_values('MDI_importance', ascending=False)\n","\n","print(df_imp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufHUodn6E4s3","executionInfo":{"status":"ok","timestamp":1744982783397,"user_tz":240,"elapsed":16380,"user":{"displayName":"Ahmad Aghapour","userId":"10024107043211715538"}},"outputId":"cb1d0b82-8ff7-4b9f-a518-b43d5b0f9bfb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["             feature  MDI_importance\n","2  petal length (cm)        0.436130\n","3   petal width (cm)        0.436065\n","0  sepal length (cm)        0.106128\n","1   sepal width (cm)        0.021678\n"]}]},{"cell_type":"markdown","source":["\n","\n","## Mean Decrease in Accuracy (MDA) / Permutation Importance\n","\n","**Idea:** “How much does model performance drop if I break feature $j$?”  \n","> **$ \\text{Importance}_j = \\text{Baseline score} - \\text{Permuted score} $**\n","\n","---\n","\n","### 1. Quick Recipe\n","1. **Choose metric** (e.g. accuracy, AUC, $R^2$, MAE)  \n","2. **Baseline**: evaluate model on held‑out data → $ \\text{score}_0 $  \n","3. **For each feature $j$**  \n","   - Shuffle column $j$ in $X_{\\text{val}}$  \n","   - Recompute $ \\text{score}_j $  \n","   - $ \\text{Drop}_j = \\text{score}_0 - \\text{score}_j $  \n","4. **Repeat** $n$ times & average to reduce noise  \n","\n"],"metadata":{"id":"yREpSC5QFLO4"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.inspection import permutation_importance\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# 1. Data split\n","X, y = load_iris(return_X_y=True)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# 2. Train\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 3. Permutation importance\n","results = permutation_importance(\n","    model, X_val, y_val,\n","    n_repeats=10,\n","    random_state=42,\n","    scoring='accuracy'\n",")\n","imp_df = pd.DataFrame({\n","    'feature': load_iris().feature_names,\n","    'mean_drop': results.importances_mean,\n","    'std_drop': results.importances_std\n","}).sort_values('mean_drop', ascending=False)\n","\n","print(imp_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ChvaqVIFR0K","executionInfo":{"status":"ok","timestamp":1744985785427,"user_tz":240,"elapsed":719,"user":{"displayName":"Ahmad Aghapour","userId":"10024107043211715538"}},"outputId":"61441824-69d4-42e6-c4cb-8ff24c95fdf2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["             feature  mean_drop  std_drop\n","3   petal width (cm)   0.175556  0.036447\n","2  petal length (cm)   0.144444  0.038809\n","1   sepal width (cm)   0.000000  0.000000\n","0  sepal length (cm)   0.000000  0.000000\n"]}]},{"cell_type":"markdown","source":["s\n","x"],"metadata":{"id":"sAlaHLl7FlYt"}},{"cell_type":"markdown","source":["## Local Surrogate Methods (e.g. LIME)\n","\n","**Key idea:** Fit a simple interpretable model in a small neighborhood around one instance to explain its prediction.\n","\n","---\n","\n","### 1. Quick Recipe\n","1. **Select** instance $x_0$.  \n","2. **Generate** $N$ perturbed samples $\\{x^{(i)}\\}$ near $x_0$.  \n","3. **Predict** black‑box outputs $y^{(i)} = f(x^{(i)})$.  \n","4. **Weight** each sample by proximity $w_i$.  \n","5. **Fit** weighted simple model $g$ (e.g. sparse linear):  \n","   $$\n","   \\min_g \\sum_i w_i\\,(y^{(i)} - g(x^{(i)}))^2 + \\Omega(g)\n","   $$\n","6. **Read off** $g$’s coefficients or rules as local explanations.\n"],"metadata":{"id":"8IZicGvFc506"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from lime.lime_tabular import LimeTabularExplainer\n","\n","# 1. Load & split\n","X, y = load_iris(return_X_y=True)\n","feature_names = load_iris().feature_names\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# 2. Train black‑box\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 3. Explain one instance\n","i = 0\n","explainer = LimeTabularExplainer(\n","    X_train,\n","    feature_names=feature_names,\n","    class_names=load_iris().target_names,\n","    discretize_continuous=True\n",")\n","exp = explainer.explain_instance(\n","    X_test[i],\n","    model.predict_proba,\n","    num_features=4\n",")\n","\n","# 4. Show local feature weights\n","print(exp.as_list())"],"metadata":{"id":"lUtQXdjCFm33"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Intuition: SHAP as “Fair Credit Assignment”\n","\n","Imagine you and friends jointly win a prize of \\$100. You want to split it fairly based on each person’s contribution. Shapley values do exactly that for features: they ask, “How much extra value does feature $j$ bring when added to any coalition of other features?”\n","\n","1. **Baseline**  \n","   Think of the baseline as the prize if no one contributed:  \n","   $$\n","   \\phi_0 = \\mathbb E[f(X)].\n","   $$\n","2. **Marginal Contribution**  \n","   For each feature $j$, consider every possible group $S$ of the other features:\n","   - Measure $f_{S\\cup\\{j\\}}(x)$: prediction when you “add” feature $j$ to $S$.\n","   - Subtract $f_S(x)$: prediction with only $S$.\n","   - That difference is $j$’s marginal contribution in coalition $S$.\n","3. **Weighted Average**  \n","   Weight each coalition by how many ways it could form:\n","   $$\n","   \\frac{|S|!\\,(d-|S|-1)!}{d!}.\n","   $$\n","   This ensures symmetry and efficiency (total adds up correctly).\n","\n","The result $\\phi_j$ tells you, on average, how much feature $j$ increased (or decreased) the prediction relative to the baseline.\n","\n","---\n","\n","## Step‐by‐Step Breakdown\n","\n","1. **Choose background** $B$  \n","   A set of “reference” samples to estimate $\\mathbb E[f(X)]$ and $f_S(x)$.\n","2. **Simplify inputs**  \n","   Encode presence/absence of each feature as a binary vector $z'\\in\\{0,1\\}^d$.\n","3. **Define surrogate**  \n","   $$\n","   g(z') = \\phi_0 + \\sum_{j=1}^d \\phi_j\\,z'_j.\n","   $$\n","4. **Fit surrogate** by minimizing weighted loss  \n","   $$\n","   \\min_{\\phi}\\; \\sum_{z'} \\pi_x(z')\\,\\bigl(f(h_x(z')) - g(z')\\bigr)^2,\n","   $$\n","   where $h_x(z')$ fills in original feature values when $z'_j=1$ and samples from $B$ when $z'_j=0$, and\n","   $$\n","   \\pi_x(z') = \\frac{(d-1)}{\\binom{d}{|z'|}\\,|z'|\\,(d-|z'|)}.\n","   $$\n","\n","---\n","\n","## Toy Example (2 Features)\n","\n","Model: $$f(x) = 10 + 2x_1 + 3x_2.$$\n","\n","Instance: $x=(x_1=1,\\;x_2=2)$.\n","\n","- Baseline: $\\mathbb E[f(X)] = 10$ (if we center $x_1,x_2$).\n","- Coalitions for feature 1:\n","  - $S=\\varnothing$: $f_{\\{1\\}}(x)=10+2\\cdot1=12$, $f_{\\varnothing}(x)=10$ → marginal = $2$.\n","  - $S=\\{2\\}$: $f_{\\{1,2\\}}(x)=10+2\\cdot1+3\\cdot2=18$, $f_{\\{2\\}}(x)=10+3\\cdot2=16$ → marginal = $2$.\n","  - Weight for each: $\\tfrac{0!1!}{2!}=½$; $\\tfrac{1!0!}{2!}=½$.\n","  - $\\phi_1 = ½\\cdot2 + ½\\cdot2 = 2$.\n","- Similarly for feature 2: $\\phi_2 = 3$ × (½+½) = 3 × 1 = 3.\n","- Check: $10 + 2 + 3 = 15 = f(x)$.\n","\n","So SHAP gives $\\phi_1=2,\\ \\phi_2=3$ exactly matching our model’s weights.\n","\n","---\n","\n","## Why SHAP Matters\n","\n","- **Fairness**: satisfies efficiency, symmetry, dummy, linearity.\n","- **Consistency**: adding a stronger feature cannot decrease its attribution.\n","- **Local & Global coherence**: you get exact local decompositions; averaging $|\\phi_j|$ yields faithful global importance.\n","- **Model‑specific optimizations**:  \n","  - **TreeSHAP** computes exact values in $O(TL^2)$.  \n","  - **KernelSHAP** approximates with weighted regression.\n","\n","---\n","\n","## Practical Tips\n","\n","- **Choose background wisely**: sample ~50–200 representative points.\n","- **Use fast algorithms**: `TreeExplainer` for trees; `KernelExplainer` sparingly on ≤ 1000 background points.\n","- **Visualize**:  \n","  - **Force plot** for single predictions  \n","  - **Summary plot** (beeswarm) for global view  \n","  - **Dependence plot** for feature effects\n","- **Watch for pitfalls**: correlated features, baseline choice, computational cost.\n"],"metadata":{"id":"cFdh1-XNGCfg"}}]}